{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vision_transformer_dls.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scvwNbJZ_cnh",
        "outputId": "09ea1c3b-7a50-473a-9f5f-9be7fab0a595"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ3miZbV_1QQ"
      },
      "source": [
        "from IPython.display import clear_output \n",
        "!pip install kaggle --upgrade\n",
        "!mkdir -p ~/.kaggle/ && cp /content/drive/MyDrive/kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c cassava-leaf-disease-classification\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_GLEjxLB0uB"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version 1.7\n",
        "!pip install timm\n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkjpt_5DOquN"
      },
      "source": [
        "!unzip /content/drive/MyDrive/train_images.zip -d /content/train_images/\n",
        "clear_output()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndfvxOLWPjir"
      },
      "source": [
        "try:\n",
        "    import os\n",
        "    os.makedirs(\"/content/test_images\")\n",
        "except FileExistsError:\n",
        "    # directory already exists\n",
        "    pass\n",
        "\n",
        "from shutil import copy2\n",
        "\n",
        "for file in os.listdir('/content/'):\n",
        "    if file.endswith('.jpg'):\n",
        "        print(file)\n",
        "        copy2('/content/'+str(file), '/content/test_images')\n",
        "clear_output()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jkmDSrJAjk8",
        "outputId": "995e8526-646c-4603-9ea3-3081610e0fe6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "import timm\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn import model_selection, metrics"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZadE2EFAByUN"
      },
      "source": [
        "# For parallelization in TPUs\n",
        "os.environ[\"XLA_USE_BF16\"] = \"1\"\n",
        "os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjzBnn-vD0pR"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproductibility of results\n",
        "    \n",
        "    Arguments:\n",
        "        seed {int} -- Number of the seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "seed_everything(1337)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hr0CxQqD3rb"
      },
      "source": [
        "# general global variables\n",
        "DATA_PATH = \"/content/\"\n",
        "TRAIN_PATH = \"/content/train_images/\"\n",
        "TEST_PATH = \"/content/train_images/\"\n",
        "\n",
        "#MODEL_PATH = (\"\")\n",
        "\n",
        "# model specific global variables\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-05\n",
        "GAMMA = 0.7\n",
        "N_EPOCHS = 20"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "dvDbM33uD5ai",
        "outputId": "cff7d031-f2c2-42a5-8c6c-5d3691cccf02"
      },
      "source": [
        "df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000015157.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000201771.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100042118.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000723321.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000812911.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_id  label\n",
              "0  1000015157.jpg      0\n",
              "1  1000201771.jpg      3\n",
              "2   100042118.jpg      1\n",
              "3  1000723321.jpg      1\n",
              "4  1000812911.jpg      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXqtBGcSD7xc"
      },
      "source": [
        "train_df, valid_df = model_selection.train_test_split(\n",
        "    df, test_size=0.1, random_state=42, stratify=df.label.values\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tid7gBxJHbYp"
      },
      "source": [
        "class CassavaDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Helper Class to create the pytorch dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n",
        "        super().__init__()\n",
        "        self.df_data = df.values\n",
        "        self.data_path = data_path\n",
        "        self.transforms = transforms\n",
        "        self.mode = mode\n",
        "        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name, label = self.df_data[index]\n",
        "        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(img)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFUqlv_dHryl"
      },
      "source": [
        "# create image augmentations\n",
        "transforms_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.RandomVerticalFlip(p=0.3),\n",
        "        transforms.RandomResizedCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transforms_valid = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9h9xvGHHtPo",
        "outputId": "02fa634a-10d5-4653-c807-a0d4487060a5"
      },
      "source": [
        "print(\"Available Vision Transformer Models: \")\n",
        "timm.list_models(\"vit*\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available Vision Transformer Models: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vit_base_patch16_224',\n",
              " 'vit_base_patch16_384',\n",
              " 'vit_base_patch32_384',\n",
              " 'vit_base_resnet26d_224',\n",
              " 'vit_base_resnet50d_224',\n",
              " 'vit_huge_patch16_224',\n",
              " 'vit_huge_patch32_384',\n",
              " 'vit_large_patch16_224',\n",
              " 'vit_large_patch16_384',\n",
              " 'vit_large_patch32_384',\n",
              " 'vit_small_patch16_224',\n",
              " 'vit_small_resnet26d_224',\n",
              " 'vit_small_resnet50d_s3_224']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsb4BtC3Hujw"
      },
      "source": [
        "class ViTBase16(nn.Module):\n",
        "    def __init__(self, n_classes, pretrained=False):\n",
        "\n",
        "        super(ViTBase16, self).__init__()\n",
        "\n",
        "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
        "        if pretrained:\n",
        "            self.model.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def train_one_epoch(self, train_loader, criterion, optimizer, device):\n",
        "        # keep track of training loss\n",
        "        epoch_loss = 0.0\n",
        "        epoch_accuracy = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        self.model.train()\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device.type == \"cuda\":\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            elif device.type == \"xla\":\n",
        "                data = data.to(device, dtype=torch.float32)\n",
        "                target = target.to(device, dtype=torch.int64)\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = self.forward(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # Calculate Accuracy\n",
        "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "            # update training loss and accuracy\n",
        "            epoch_loss += loss\n",
        "            epoch_accuracy += accuracy\n",
        "\n",
        "            # perform a single optimization step (parameter update)\n",
        "            if device.type == \"xla\":\n",
        "                xm.optimizer_step(optimizer)\n",
        "\n",
        "                if i % 20 == 0:\n",
        "                    xm.master_print(f\"\\tBATCH {i+1}/{len(train_loader)} - LOSS: {loss}\")\n",
        "\n",
        "            else:\n",
        "                optimizer.step()\n",
        "\n",
        "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
        "\n",
        "    def validate_one_epoch(self, valid_loader, criterion, device):\n",
        "        # keep track of validation loss\n",
        "        valid_loss = 0.0\n",
        "        valid_accuracy = 0.0\n",
        "\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        self.model.eval()\n",
        "        for data, target in valid_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device.type == \"cuda\":\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            elif device.type == \"xla\":\n",
        "                data = data.to(device, dtype=torch.float32)\n",
        "                target = target.to(device, dtype=torch.int64)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # forward pass: compute predicted outputs by passing inputs to the model\n",
        "                output = self.model(data)\n",
        "                # calculate the batch loss\n",
        "                loss = criterion(output, target)\n",
        "                # Calculate Accuracy\n",
        "                accuracy = (output.argmax(dim=1) == target).float().mean()\n",
        "                # update average validation loss and accuracy\n",
        "                valid_loss += loss\n",
        "                valid_accuracy += accuracy\n",
        "\n",
        "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7cjRXBsHx_E"
      },
      "source": [
        "def fit_tpu(\n",
        "    model, epochs, device, criterion, optimizer, train_loader, valid_loader=None\n",
        "):\n",
        "\n",
        "    valid_loss_min = np.Inf  # track change in validation loss\n",
        "\n",
        "    # keeping track of losses as it happen\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    train_accs = []\n",
        "    valid_accs = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        gc.collect()\n",
        "        para_train_loader = pl.ParallelLoader(train_loader, [device])\n",
        "\n",
        "        xm.master_print(f\"{'='*50}\")\n",
        "        xm.master_print(f\"EPOCH {epoch} - TRAINING...\")\n",
        "        train_loss, train_acc = model.train_one_epoch(\n",
        "            para_train_loader.per_device_loader(device), criterion, optimizer, device\n",
        "        )\n",
        "        xm.master_print(\n",
        "            f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\n\"\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        gc.collect()\n",
        "\n",
        "        if valid_loader is not None:\n",
        "            gc.collect()\n",
        "            para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n",
        "            xm.master_print(f\"EPOCH {epoch} - VALIDATING...\")\n",
        "            valid_loss, valid_acc = model.validate_one_epoch(\n",
        "                para_valid_loader.per_device_loader(device), criterion, device\n",
        "            )\n",
        "            xm.master_print(f\"\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\n\")\n",
        "            valid_losses.append(valid_loss)\n",
        "            valid_accs.append(valid_acc)\n",
        "            gc.collect()\n",
        "\n",
        "            # save model if validation loss has decreased\n",
        "            if valid_loss <= valid_loss_min and epoch != 1:\n",
        "                xm.master_print(\n",
        "                    \"Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...\".format(\n",
        "                        valid_loss_min, valid_loss\n",
        "                    )\n",
        "                )\n",
        "            #                 xm.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "    return {\n",
        "        \"train_loss\": train_losses,\n",
        "        \"valid_losses\": valid_losses,\n",
        "        \"train_acc\": train_accs,\n",
        "        \"valid_acc\": valid_accs,\n",
        "    }\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4JcQQn0H0OA"
      },
      "source": [
        "model = ViTBase16(n_classes=5, pretrained=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgRYCZ01H1ar"
      },
      "source": [
        "def _run():\n",
        "    train_dataset = CassavaDataset(train_df, transforms=transforms_train)\n",
        "    valid_dataset = CassavaDataset(valid_df, transforms=transforms_valid)\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        train_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        valid_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=8,\n",
        "    )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        dataset=valid_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        sampler=valid_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=8,\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = xm.xla_device()\n",
        "    model.to(device)\n",
        "\n",
        "    lr = LR * xm.xrt_world_size()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    xm.master_print(f\"INITIALIZING TRAINING ON {xm.xrt_world_size()} TPU CORES\")\n",
        "    start_time = datetime.now()\n",
        "    xm.master_print(f\"Start Time: {start_time}\")\n",
        "\n",
        "    logs = fit_tpu(\n",
        "        model=model,\n",
        "        epochs=N_EPOCHS,\n",
        "        device=device,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        train_loader=train_loader,\n",
        "        valid_loader=valid_loader,\n",
        "    )\n",
        "\n",
        "    xm.master_print(f\"Execution time: {datetime.now() - start_time}\")\n",
        "\n",
        "    xm.master_print(\"Saving Model\")\n",
        "    xm.save(\n",
        "        model.state_dict(), f'/content/drive/MyDrive/model_5e_{datetime.now().strftime(\"%Y%m%d-%H%M\")}.pth'\n",
        "    )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HivYfR0H54o",
        "outputId": "2836ca20-c0f7-4b05-e7e4-f8e4cc91ebc0"
      },
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "    a = _run()\n",
        "\n",
        "\n",
        "# _run()\n",
        "FLAGS = {}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method=\"fork\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INITIALIZING TRAINING ON 8 TPU CORES\n",
            "Start Time: 2021-02-02 11:05:45.032682\n",
            "==================================================\n",
            "EPOCH 1 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 1.8359375\n",
            "\tBATCH 21/150 - LOSS: 1.203125\n",
            "\tBATCH 41/150 - LOSS: 0.84375\n",
            "\tBATCH 61/150 - LOSS: 1.28125\n",
            "\tBATCH 81/150 - LOSS: 1.28125\n",
            "\tBATCH 101/150 - LOSS: 1.5546875\n",
            "\tBATCH 121/150 - LOSS: 1.0546875\n",
            "\tBATCH 141/150 - LOSS: 1.03125\n",
            "\n",
            "\t[TRAIN] EPOCH 1 - LOSS: 1.1875, ACCURACY: 0.6015625\n",
            "\n",
            "EPOCH 1 - VALIDATING...\n",
            "\t[VALID] LOSS: 1.1953125, ACCURACY: 0.59765625\n",
            "\n",
            "==================================================\n",
            "EPOCH 2 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 1.0546875\n",
            "\tBATCH 21/150 - LOSS: 1.1640625\n",
            "\tBATCH 41/150 - LOSS: 0.6484375\n",
            "\tBATCH 61/150 - LOSS: 1.1484375\n",
            "\tBATCH 81/150 - LOSS: 1.0625\n",
            "\tBATCH 101/150 - LOSS: 1.4375\n",
            "\tBATCH 121/150 - LOSS: 1.03125\n",
            "\tBATCH 141/150 - LOSS: 0.81640625\n",
            "\n",
            "\t[TRAIN] EPOCH 2 - LOSS: 1.0859375, ACCURACY: 0.6171875\n",
            "\n",
            "EPOCH 2 - VALIDATING...\n",
            "\t[VALID] LOSS: 1.03125, ACCURACY: 0.6171875\n",
            "\n",
            "Validation loss decreased (1.1953 --> 1.0312).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 3 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.7734375\n",
            "\tBATCH 21/150 - LOSS: 0.8828125\n",
            "\tBATCH 41/150 - LOSS: 0.50390625\n",
            "\tBATCH 61/150 - LOSS: 1.2265625\n",
            "\tBATCH 81/150 - LOSS: 0.92578125\n",
            "\tBATCH 101/150 - LOSS: 1.125\n",
            "\tBATCH 121/150 - LOSS: 0.9140625\n",
            "\tBATCH 141/150 - LOSS: 0.6171875\n",
            "\n",
            "\t[TRAIN] EPOCH 3 - LOSS: 0.98046875, ACCURACY: 0.640625\n",
            "\n",
            "EPOCH 3 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.9765625, ACCURACY: 0.6328125\n",
            "\n",
            "Validation loss decreased (1.0312 --> 0.9766).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 4 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.69140625\n",
            "\tBATCH 21/150 - LOSS: 0.8515625\n",
            "\tBATCH 41/150 - LOSS: 0.51953125\n",
            "\tBATCH 61/150 - LOSS: 0.97265625\n",
            "\tBATCH 81/150 - LOSS: 0.87890625\n",
            "\tBATCH 101/150 - LOSS: 1.015625\n",
            "\tBATCH 121/150 - LOSS: 0.8671875\n",
            "\tBATCH 141/150 - LOSS: 0.83203125\n",
            "\n",
            "\t[TRAIN] EPOCH 4 - LOSS: 0.88671875, ACCURACY: 0.66015625\n",
            "\n",
            "EPOCH 4 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.9453125, ACCURACY: 0.66015625\n",
            "\n",
            "Validation loss decreased (0.9766 --> 0.9453).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 5 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.74609375\n",
            "\tBATCH 21/150 - LOSS: 0.78515625\n",
            "\tBATCH 41/150 - LOSS: 0.404296875\n",
            "\tBATCH 61/150 - LOSS: 0.984375\n",
            "\tBATCH 81/150 - LOSS: 0.98828125\n",
            "\tBATCH 101/150 - LOSS: 1.0625\n",
            "\tBATCH 121/150 - LOSS: 0.6953125\n",
            "\tBATCH 141/150 - LOSS: 0.6484375\n",
            "\n",
            "\t[TRAIN] EPOCH 5 - LOSS: 0.8671875, ACCURACY: 0.6796875\n",
            "\n",
            "EPOCH 5 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.921875, ACCURACY: 0.6328125\n",
            "\n",
            "Validation loss decreased (0.9453 --> 0.9219).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 6 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.6953125\n",
            "\tBATCH 21/150 - LOSS: 0.91015625\n",
            "\tBATCH 41/150 - LOSS: 0.4453125\n",
            "\tBATCH 61/150 - LOSS: 1.0\n",
            "\tBATCH 81/150 - LOSS: 0.828125\n",
            "\tBATCH 101/150 - LOSS: 0.8828125\n",
            "\tBATCH 121/150 - LOSS: 0.6484375\n",
            "\tBATCH 141/150 - LOSS: 0.58203125\n",
            "\n",
            "\t[TRAIN] EPOCH 6 - LOSS: 0.8203125, ACCURACY: 0.6875\n",
            "\n",
            "EPOCH 6 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.8828125, ACCURACY: 0.640625\n",
            "\n",
            "Validation loss decreased (0.9219 --> 0.8828).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 7 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.765625\n",
            "\tBATCH 21/150 - LOSS: 0.9609375\n",
            "\tBATCH 41/150 - LOSS: 0.349609375\n",
            "\tBATCH 61/150 - LOSS: 0.75\n",
            "\tBATCH 81/150 - LOSS: 0.90234375\n",
            "\tBATCH 101/150 - LOSS: 0.921875\n",
            "\tBATCH 121/150 - LOSS: 0.53515625\n",
            "\tBATCH 141/150 - LOSS: 0.578125\n",
            "\n",
            "\t[TRAIN] EPOCH 7 - LOSS: 0.7890625, ACCURACY: 0.69140625\n",
            "\n",
            "EPOCH 7 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.8984375, ACCURACY: 0.6328125\n",
            "\n",
            "==================================================\n",
            "EPOCH 8 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.5390625\n",
            "\tBATCH 21/150 - LOSS: 0.67578125\n",
            "\tBATCH 41/150 - LOSS: 0.412109375\n",
            "\tBATCH 61/150 - LOSS: 0.7421875\n",
            "\tBATCH 81/150 - LOSS: 0.8984375\n",
            "\tBATCH 101/150 - LOSS: 0.9375\n",
            "\tBATCH 121/150 - LOSS: 0.66015625\n",
            "\tBATCH 141/150 - LOSS: 0.6328125\n",
            "\n",
            "\t[TRAIN] EPOCH 8 - LOSS: 0.765625, ACCURACY: 0.70703125\n",
            "\n",
            "EPOCH 8 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.8359375, ACCURACY: 0.66796875\n",
            "\n",
            "Validation loss decreased (0.8984 --> 0.8359).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 9 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.515625\n",
            "\tBATCH 21/150 - LOSS: 0.8046875\n",
            "\tBATCH 41/150 - LOSS: 0.447265625\n",
            "\tBATCH 61/150 - LOSS: 0.8515625\n",
            "\tBATCH 81/150 - LOSS: 0.79296875\n",
            "\tBATCH 101/150 - LOSS: 0.921875\n",
            "\tBATCH 121/150 - LOSS: 0.61328125\n",
            "\tBATCH 141/150 - LOSS: 0.63671875\n",
            "\n",
            "\t[TRAIN] EPOCH 9 - LOSS: 0.7578125, ACCURACY: 0.71484375\n",
            "\n",
            "EPOCH 9 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.8515625, ACCURACY: 0.68359375\n",
            "\n",
            "==================================================\n",
            "EPOCH 10 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.64453125\n",
            "\tBATCH 21/150 - LOSS: 0.85546875\n",
            "\tBATCH 41/150 - LOSS: 0.326171875\n",
            "\tBATCH 61/150 - LOSS: 0.7265625\n",
            "\tBATCH 81/150 - LOSS: 0.87109375\n",
            "\tBATCH 101/150 - LOSS: 1.015625\n",
            "\tBATCH 121/150 - LOSS: 0.56640625\n",
            "\tBATCH 141/150 - LOSS: 0.546875\n",
            "\n",
            "\t[TRAIN] EPOCH 10 - LOSS: 0.7734375, ACCURACY: 0.7265625\n",
            "\n",
            "EPOCH 10 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.85546875, ACCURACY: 0.65625\n",
            "\n",
            "==================================================\n",
            "EPOCH 11 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.6015625\n",
            "\tBATCH 21/150 - LOSS: 0.78125\n",
            "\tBATCH 41/150 - LOSS: 0.39453125\n",
            "\tBATCH 61/150 - LOSS: 0.72265625\n",
            "\tBATCH 81/150 - LOSS: 0.73828125\n",
            "\tBATCH 101/150 - LOSS: 0.96484375\n",
            "\tBATCH 121/150 - LOSS: 0.6953125\n",
            "\tBATCH 141/150 - LOSS: 0.640625\n",
            "\n",
            "\t[TRAIN] EPOCH 11 - LOSS: 0.7578125, ACCURACY: 0.74609375\n",
            "\n",
            "EPOCH 11 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.8359375, ACCURACY: 0.66796875\n",
            "\n",
            "Validation loss decreased (0.8555 --> 0.8359).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 12 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.48046875\n",
            "\tBATCH 21/150 - LOSS: 0.49609375\n",
            "\tBATCH 41/150 - LOSS: 0.326171875\n",
            "\tBATCH 61/150 - LOSS: 0.65234375\n",
            "\tBATCH 81/150 - LOSS: 0.875\n",
            "\tBATCH 101/150 - LOSS: 0.8828125\n",
            "\tBATCH 121/150 - LOSS: 0.58984375\n",
            "\tBATCH 141/150 - LOSS: 0.56640625\n",
            "\n",
            "\t[TRAIN] EPOCH 12 - LOSS: 0.73046875, ACCURACY: 0.71875\n",
            "\n",
            "EPOCH 12 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.8203125, ACCURACY: 0.6796875\n",
            "\n",
            "Validation loss decreased (0.8359 --> 0.8203).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 13 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.52734375\n",
            "\tBATCH 21/150 - LOSS: 0.84765625\n",
            "\tBATCH 41/150 - LOSS: 0.3203125\n",
            "\tBATCH 61/150 - LOSS: 0.5703125\n",
            "\tBATCH 81/150 - LOSS: 0.79296875\n",
            "\tBATCH 101/150 - LOSS: 1.1796875\n",
            "\tBATCH 121/150 - LOSS: 0.474609375\n",
            "\tBATCH 141/150 - LOSS: 0.462890625\n",
            "\n",
            "\t[TRAIN] EPOCH 13 - LOSS: 0.71484375, ACCURACY: 0.75\n",
            "\n",
            "EPOCH 13 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.8359375, ACCURACY: 0.6875\n",
            "\n",
            "==================================================\n",
            "EPOCH 14 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.73046875\n",
            "\tBATCH 21/150 - LOSS: 0.57421875\n",
            "\tBATCH 41/150 - LOSS: 0.3671875\n",
            "\tBATCH 61/150 - LOSS: 0.4921875\n",
            "\tBATCH 81/150 - LOSS: 0.6171875\n",
            "\tBATCH 101/150 - LOSS: 1.0234375\n",
            "\tBATCH 121/150 - LOSS: 0.609375\n",
            "\tBATCH 141/150 - LOSS: 0.6484375\n",
            "\n",
            "\t[TRAIN] EPOCH 14 - LOSS: 0.71484375, ACCURACY: 0.73828125\n",
            "\n",
            "EPOCH 14 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.796875, ACCURACY: 0.68359375\n",
            "\n",
            "Validation loss decreased (0.8359 --> 0.7969).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 15 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.56640625\n",
            "\tBATCH 21/150 - LOSS: 0.6640625\n",
            "\tBATCH 41/150 - LOSS: 0.34765625\n",
            "\tBATCH 61/150 - LOSS: 0.51171875\n",
            "\tBATCH 81/150 - LOSS: 0.8515625\n",
            "\tBATCH 101/150 - LOSS: 0.9375\n",
            "\tBATCH 121/150 - LOSS: 0.546875\n",
            "\tBATCH 141/150 - LOSS: 0.435546875\n",
            "\n",
            "\t[TRAIN] EPOCH 15 - LOSS: 0.72265625, ACCURACY: 0.73828125\n",
            "\n",
            "EPOCH 15 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.80859375, ACCURACY: 0.6953125\n",
            "\n",
            "==================================================\n",
            "EPOCH 16 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.6328125\n",
            "\tBATCH 21/150 - LOSS: 0.4453125\n",
            "\tBATCH 41/150 - LOSS: 0.3984375\n",
            "\tBATCH 61/150 - LOSS: 0.64453125\n",
            "\tBATCH 81/150 - LOSS: 0.6328125\n",
            "\tBATCH 101/150 - LOSS: 0.9453125\n",
            "\tBATCH 121/150 - LOSS: 0.546875\n",
            "\tBATCH 141/150 - LOSS: 0.494140625\n",
            "\n",
            "\t[TRAIN] EPOCH 16 - LOSS: 0.70703125, ACCURACY: 0.75\n",
            "\n",
            "EPOCH 16 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.8046875, ACCURACY: 0.703125\n",
            "\n",
            "Validation loss decreased (0.8086 --> 0.8047).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 17 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.435546875\n",
            "\tBATCH 21/150 - LOSS: 0.546875\n",
            "\tBATCH 41/150 - LOSS: 0.373046875\n",
            "\tBATCH 61/150 - LOSS: 0.55859375\n",
            "\tBATCH 81/150 - LOSS: 0.8515625\n",
            "\tBATCH 101/150 - LOSS: 0.92578125\n",
            "\tBATCH 121/150 - LOSS: 0.53515625\n",
            "\tBATCH 141/150 - LOSS: 0.578125\n",
            "\n",
            "\t[TRAIN] EPOCH 17 - LOSS: 0.68359375, ACCURACY: 0.7421875\n",
            "\n",
            "EPOCH 17 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.80078125, ACCURACY: 0.734375\n",
            "\n",
            "Validation loss decreased (0.8047 --> 0.8008).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 18 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.61328125\n",
            "\tBATCH 21/150 - LOSS: 0.671875\n",
            "\tBATCH 41/150 - LOSS: 0.44921875\n",
            "\tBATCH 61/150 - LOSS: 0.7890625\n",
            "\tBATCH 81/150 - LOSS: 0.828125\n",
            "\tBATCH 101/150 - LOSS: 0.76171875\n",
            "\tBATCH 121/150 - LOSS: 0.51953125\n",
            "\tBATCH 141/150 - LOSS: 0.45703125\n",
            "\n",
            "\t[TRAIN] EPOCH 18 - LOSS: 0.68359375, ACCURACY: 0.74609375\n",
            "\n",
            "EPOCH 18 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.82421875, ACCURACY: 0.671875\n",
            "\n",
            "==================================================\n",
            "EPOCH 19 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.67578125\n",
            "\tBATCH 21/150 - LOSS: 0.3671875\n",
            "\tBATCH 41/150 - LOSS: 0.31640625\n",
            "\tBATCH 61/150 - LOSS: 0.50390625\n",
            "\tBATCH 81/150 - LOSS: 0.671875\n",
            "\tBATCH 101/150 - LOSS: 0.85546875\n",
            "\tBATCH 121/150 - LOSS: 0.7109375\n",
            "\tBATCH 141/150 - LOSS: 0.447265625\n",
            "\n",
            "\t[TRAIN] EPOCH 19 - LOSS: 0.6640625, ACCURACY: 0.7890625\n",
            "\n",
            "EPOCH 19 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.7890625, ACCURACY: 0.69921875\n",
            "\n",
            "Validation loss decreased (0.8242 --> 0.7891).  Saving model ...\n",
            "==================================================\n",
            "EPOCH 20 - TRAINING...\n",
            "\tBATCH 1/150 - LOSS: 0.38671875\n",
            "\tBATCH 21/150 - LOSS: 0.41015625\n",
            "\tBATCH 41/150 - LOSS: 0.3828125\n",
            "\tBATCH 61/150 - LOSS: 0.423828125\n",
            "\tBATCH 81/150 - LOSS: 0.74609375\n",
            "\tBATCH 101/150 - LOSS: 0.9921875\n",
            "\tBATCH 121/150 - LOSS: 0.6015625\n",
            "\tBATCH 141/150 - LOSS: 0.486328125\n",
            "\n",
            "\t[TRAIN] EPOCH 20 - LOSS: 0.69140625, ACCURACY: 0.75\n",
            "\n",
            "EPOCH 20 - VALIDATING...\n",
            "\t[VALID] LOSS: 0.78515625, ACCURACY: 0.7109375\n",
            "\n",
            "Validation loss decreased (0.7891 --> 0.7852).  Saving model ...\n",
            "Execution time: 0:20:07.333143\n",
            "Saving Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvA66CJDH765"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}