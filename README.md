## Project for Deep Learning School (2nd part) - Vision Transformer

**Dont forget to check:** Multi head attention map, [link on dropbox](https://www.dropbox.com/s/a63gf5563t75lbv/vision-transformer-vit-visualize-multi-head-attention-map.ipynb?dl=0)
 
My task is research and realize vision transformer to classify images
 
**Task:** classifcation model with transformer architecture  

**Dataset:** From [Kaggle competition](https://www.kaggle.com/c/cassava-leaf-disease-classification) 
 
**Input:** photo 224x224x3

**Loss:** `CrossEntropyLoss`
 
**Metric:** Accuracy

Trained for `20` epochs on `TPU`, best accuracy `~79%`
 
## What is Vision Transformer?

Let's look on this interpritation

![image](https://www.deepdetect.com/img/blog_01_vit_arch.png)

And multihead attention

![image](https://ai.snip.today/wp-content/uploads/2019/05/vaswani1.png)
